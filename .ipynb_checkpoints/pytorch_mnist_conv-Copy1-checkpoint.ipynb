{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "trainset = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True, \n",
    "    transform = transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size = 4,\n",
    "    shuffle = True\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size = 4,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "tensor([5, 2, 4, 6])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_1 in trainloader:\n",
    "    batch = batch_1\n",
    "    break\n",
    "print(batch[0].shape) # as batch[0] contains the image pixels -> tensors\n",
    "print(batch[1]) # batch[1] contains the labels -> tensors\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range (batch[0].shape[0]):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(batch[0][i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(int(batch[1][i]))\n",
    "    plt.savefig('digit_mnist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, \n",
    "                               kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, \n",
    "                               kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=800, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1,  5000 Mini Batches] loss: 0.301\n",
      "[Epoch 1, 10000 Mini Batches] loss: 0.083\n",
      "[Epoch 1, 15000 Mini Batches] loss: 0.061\n",
      "[Epoch 2,  5000 Mini Batches] loss: 0.046\n",
      "[Epoch 2, 10000 Mini Batches] loss: 0.043\n",
      "[Epoch 2, 15000 Mini Batches] loss: 0.038\n",
      "[Epoch 3,  5000 Mini Batches] loss: 0.027\n",
      "[Epoch 3, 10000 Mini Batches] loss: 0.029\n",
      "[Epoch 3, 15000 Mini Batches] loss: 0.026\n",
      "[Epoch 4,  5000 Mini Batches] loss: 0.021\n",
      "[Epoch 4, 10000 Mini Batches] loss: 0.017\n",
      "[Epoch 4, 15000 Mini Batches] loss: 0.021\n",
      "[Epoch 5,  5000 Mini Batches] loss: 0.011\n",
      "[Epoch 5, 10000 Mini Batches] loss: 0.017\n",
      "[Epoch 5, 15000 Mini Batches] loss: 0.015\n",
      "[Epoch 6,  5000 Mini Batches] loss: 0.009\n",
      "[Epoch 6, 10000 Mini Batches] loss: 0.014\n",
      "[Epoch 6, 15000 Mini Batches] loss: 0.012\n",
      "[Epoch 7,  5000 Mini Batches] loss: 0.009\n",
      "[Epoch 7, 10000 Mini Batches] loss: 0.008\n",
      "[Epoch 7, 15000 Mini Batches] loss: 0.010\n",
      "[Epoch 8,  5000 Mini Batches] loss: 0.007\n",
      "[Epoch 8, 10000 Mini Batches] loss: 0.006\n",
      "[Epoch 8, 15000 Mini Batches] loss: 0.009\n",
      "[Epoch 9,  5000 Mini Batches] loss: 0.004\n",
      "[Epoch 9, 10000 Mini Batches] loss: 0.005\n",
      "[Epoch 9, 15000 Mini Batches] loss: 0.006\n",
      "[Epoch 10,  5000 Mini Batches] loss: 0.004\n",
      "[Epoch 10, 10000 Mini Batches] loss: 0.005\n",
      "[Epoch 10, 15000 Mini Batches] loss: 0.004\n",
      "Done Training\n",
      "5.53 minutes\n"
     ]
    }
   ],
   "source": [
    "def train(net):\n",
    "    start = time.time()\n",
    "    for epoch in range(10): # no. of epochs\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # data pixels and labels to GPU if available\n",
    "            inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
    "            # set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # propagate the loss backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print for mini batches\n",
    "            running_loss += loss.item()\n",
    "            if i % 5000 == 4999:  # every 5000 mini batches\n",
    "                print('[Epoch %d, %5d Mini Batches] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss/5000))\n",
    "                running_loss = 0.0\n",
    "    end = time.time()\n",
    "    print('Done Training')\n",
    "    print('%0.2f minutes' %((end - start) / 60))\n",
    "    \n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test images: 99.280 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on test images: %0.3f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
